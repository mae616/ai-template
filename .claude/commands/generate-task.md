# TASK作成

## 機能ファイル: $ARGUMENTS

包括的な調査を行い、一般的な機能実装のための完全なTASKを生成します。AIエージェントが自己検証と反復的な改善を行えるよう、コンテキストがTASKに渡されることを確保してください。まず機能ファイルを読み、何を作成する必要があるか、提供された例がどのように役立つか、その他の考慮事項を理解してください。

AIエージェントは、TASKとトレーニングデータに追加するコンテキストのみを取得します。AIエージェントはコードベースとあなたと同じ知識カットオフにアクセスできると仮定してください。そのため、調査結果をTASKに含めるか参照することが重要です。エージェントはWeb検索機能を持っているので、ドキュメントと例のURLを渡してください。

## 調査プロセス
APIについて実装前にAPIの公式リファレンスのURLを聞き、その内容を理解し実装できりょう調査してください。

1. **コードベース分析**
   - コードベース内で類似の機能/パターンを検索
   - TASKで参照するファイルを特定
   - 従うべき既存の規則を記録
   - 検証アプローチのためのテストパターンを確認

2. **外部調査**
   - オンラインで類似の機能/パターンを検索
   - ライブラリドキュメント（具体的なURLを含む）
   - 実装例（GitHub/StackOverflow/ブログ）
   - ベストプラクティスと一般的な落とし穴

3. **ユーザー確認**（必要に応じて）
   - 反映すべき特定のパターンとその場所？
   - 統合要件とその場所？

## TASK生成

アジャイルやスクラムのような、小さな作成や修正後、一度ユーザーに動かせる状態にして、フィードバックをもらいつつTASKを改善していってください。

特にデザインについては初期段階でユーザーに見えるようにして、フィードバックを重ねるようにしてください。

タスクのスプリントごとに出力ファイルを分けて、テンプレートに日本語で記載してください。ファイル名でタスクを実行する順番をわかるようにしてください。

ai-task/templates/task_base.mdをテンプレートとして使用：

### AIエージェントにTASKの一部として渡す重要なコンテキスト
- **ドキュメント**: 特定のセクションを含むURL
- **コード例**: コードベースからの実際のスニペット
- **注意点**: ライブラリの癖、バージョンの問題
- **パターン**: 従うべき既存のアプローチ

### 実装ブループリント
- アプローチを示す疑似コードで開始
- パターンのための実際のファイルを参照
- エラーハンドリング戦略を含む
 - TASKを満たすために完了すべきタスクを実行順にリスト化

### 検証ゲート（実行可能でなければならない）例：TypeScript
```bash
# 構文/スタイル
pnpm lint --fix && pnpm type-check

# ユニットテスト
pnpm test

```

*** コードベースの調査と探索を完了し、TASKの作成を開始する前に重要 ***

*** TASKについて深く考え、アプローチを計画してからTASKの作成を開始してください ***

## 出力
保存先: `ai-task/TASK_{sprint}_{feature-name}.md`

## 品質チェックリスト
- [ ] 必要なコンテキストがすべて含まれている
- [ ] 検証ゲートがAIによって実行可能
- [ ] 既存のパターンを参照している
- [ ] 明確な実装パス
- [ ] エラーハンドリングが文書化されている

TASKを1-10のスケールで評価してください（claude codesを使用したワンパス実装で成功する自信レベル）

覚えておいてください：目標は包括的なコンテキストによるユーザーとの共創によるスクラム実装の成功です。
